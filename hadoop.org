#+TITLE: Hadoop
#+DATE: 2014-06-02

* HAR (Hadoop Archives)
HAR 可将众多文件打包为一个 .har 文件，这样对于 HDFS 的命名空间来说，只是一个文件，
所以能够缓解 namenode 的压力。同时，HAR 还提供了透明访问的功能，用户可以指定 HAR
中的某些文件作为 MarReduce 的输入。

[[./img/hadoop-1.png]]

参考：
+ [[http://hadoop.apache.org/docs/r1.2.1/hadoop_archives.html][Hadoop Archives Guide]]
+ [[http://hadoop.apache.org/docs/r0.19.0/hadoop_archives.html][Hadoop Archives]]
+ [[http://c.hocobo.net/2010/08/05/har/][Hadoop Archive解决海量小文件存储]]
  
** 如何定位 HAR 下的某个文件（URI）
HAR 管理的文件的 URI 的模式如下：
#+BEGIN_EXAMPLE
har://scheme-hostname:port/archivepath/fileinarchive
#+END_EXAMPLE

其中，schema 是 HAR 寄生于的文件系统的类型，例如 hdfs。下面是一个实际的例子：
#+BEGIN_EXAMPLE
har://hdfs-szjjh-log-hdfs.dmop.baidu.com:54310/app/log/ps_wise_click/20140514.har/app/
#+END_EXAMPLE

该 URI 代表的文件是：位于 *szjjh-log* HDFS的 */app/log/ps_wise_click/20140514.har*
HAR 下的 */app* 目录。

* 问题搜集
** Streaming 的 Reducer 运行失败，提示：java.lang.NullPointerException
我用 Python 写了一个 MapReduce 脚本，但是在 reduce 阶段，任务总是失败。失败
信息如下：
#+BEGIN_SRC java
java.lang.NullPointerException
	at org.apache.hadoop.streaming.PipeMapRed.getContext(PipeMapRed.java:744)
	at org.apache.hadoop.streaming.PipeMapRed.logFailure(PipeMapRed.java:775)
	at org.apache.hadoop.streaming.PipeReducer.reduce(PipeReducer.java:133)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:816)
	at org.apache.hadoop.mapred.Child.main(Child.java:212)
#+END_SRC

一开始，错误信息看不出头绪，我以为我使用的集群（百度内部的 IDLE 集群，用公司的空
闲资源来提供高量低质的计算力的集群）不行，准备借一个其他好点的集群的队列。亏好我
多点了几下，进入到任务的 stderr 页面，在最下面看到了如下信息：
#+BEGIN_SRC python
Traceback (most recent call last):
  File "/home/disk6/infidle/local/normal/job_20140321151543_439979-vertex1-reduce_20140430062926-1072/appSlave/job_20140321151543_439979/attempt_20140321151543_439979_r001_000000_1002/work/./merge_pid.py", line 4, in ?
    from operator import itemgetter
ImportError: cannot import name itemgetter
#+END_SRC

这样，reduce失败的原因就很明显了，是集群的 Python 版本太低，没有内置
itemgetter模块导致的。这么是我的 reducer 脚本。
#+BEGIN_SRC python
from operator import itemgetter

pid_counts = {}
...
...
for pid, count in sorted(pid_counts.items(), key=itemgetter(1), reverse=True):
  print "pid:", pid, count
#+END_SRC

我修改了一下，不用itemgetter和sorted实现排序，而是只用用dict的原生遍历
方法来输出reduce结果后，问题解决。
#+BEGIN_SRC python
for pid in pid_counts:
  print pid, pid_counts[pid]
#+END_SRC
